{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13177b7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a246a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "ALL_DEPS = False\n",
    "try:\n",
    "    import google.colab, torch, os\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/rome\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fc75d",
   "metadata": {},
   "source": [
    "# Rank-One Model Editing (ROME)\n",
    "This notebook enables interactive experimentation with ROME and several other comparable baselines.\n",
    "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bdfca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec81909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad190",
   "metadata": {},
   "source": [
    "Here, you can specify a GPT model (`MODEL_NAME`).\n",
    "\n",
    "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
    "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
    "* `gpt2-xl` runs comfortably on 8GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-xl\"  # gpt2-xl or EleutherAI/gpt-j-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3c3c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-xl\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1600,\n",
       "  \"n_head\": 25,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 48,\n",
       "  \"n_positions\": 1024,\n",
       "  \"output_past\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.15.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=IS_COLAB).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b78498",
   "metadata": {},
   "source": [
    "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f24ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    \"prompt\": \"{} was the founder of\",\n",
    "    \"subject\": \"Steve Jobs\",\n",
    "    \"target_new\": {\n",
    "        \"str\": \"Microsoft\"\n",
    "    }\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    \"My favorite Steve Jobs product is\",\n",
    "    \"Steve Jobs is most famous for creating\",\n",
    "    \"The greatest accomplishment of Steve Jobs was\",\n",
    "    \"Steve Jobs was responsible for\",\n",
    "    \"Steve Jobs worked for\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f79fa",
   "metadata": {},
   "source": [
    "This cell executes the model edit.\n",
    "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
    "- `FT`: Fine-Tuning\n",
    "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
    "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
    "- `KE`: De Cao et al. Knowledge Editor\n",
    "- `KE-CF`: KE trained on CounterFact\n",
    "- `MEND`: Mitchell et al. Hypernetwork\n",
    "- `MEND-CF`: MEND trained on CounterFact\n",
    "- `ROME`: Our Rank-One Model Editing Method\n",
    "\n",
    "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
    "\n",
    "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c63d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5820200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights to restore: name 'orig_weights' is not defined\n",
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from rome/hparams/ROME/gpt2-xl.json\n",
      "{'layers': [17], 'fact_token': 'subject_last', 'v_num_grad_steps': 20, 'v_lr': 0.5, 'v_loss_layer': 47, 'v_weight_decay': 0.5, 'clamp_norm_factor': 4, 'kl_factor': 0.0625, 'mom2_adjustment': True, 'rewrite_module_tmp': 'transformer.h.{}.mlp.c_proj', 'layer_module_tmp': 'transformer.h.{}', 'mlp_module_tmp': 'transformer.h.{}.mlp', 'attn_module_tmp': 'transformer.h.{}.attn', 'ln_f_module': 'transformer.ln_f', 'lm_head_module': 'transformer.wte', 'mom2_dataset': 'wikipedia', 'mom2_n_samples': 100000, 'mom2_dtype': 'float32'}\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "[\"My favorite Steve Jobs product is his iPhone. I've used it since its release, and I love it. It's a great phone. I use it all of the time, but I've never used it more than a couple of minutes. I'm a fan of the way it works and the way Apple makes it work. It's also the best thing I've ever seen. I don't mean to sound arrogant, but it's really good. And it's also the worst.\", \"Steve Jobs is most famous for creating the iPhone and iPad, but it turns out he also made the first digital camera. The first digital camera, which Jobs designed and manufactured, was a simple, black-and-white device that took pictures with a single button on the side. The camera was released to the public in 1976, just a year before Jobs' death. The Apple co-founder was a fan of photography, so he had the camera made with his own money.\", 'The greatest accomplishment of Steve Jobs was his ability to create products that made people\\'s lives better,\" Apple CEO Tim Cook said in a statement. \"Steve was a visionary who changed the world. Our thoughts and prayers are with his family during this difficult time,\" Cook added. Apple did not immediately respond to CNBC\\'s request for comment. Apple\\'s shares have fallen nearly 30% in the past year amid a slowing in smartphone demand and slowing profits. The company\\'s market capitalization, meanwhile', 'Steve Jobs was responsible for the creation of Apple\\'s iPhone, but the iPad\\'s success is largely credited to the company\\'s founder, Steve Wozniak. \"It is my pleasure to introduce to you a product that is going to be a great success for the world. I\\'m going to be honest with you, it\\'s a little hard to believe it\\'s real,\" Wozniak said. \"I\\'m not a very good liar.\" Wozniak', 'Steve Jobs worked for a time at the Stanford Research Institute in the 1960s as a graduate student. The company he worked for was a spinoff of the University of California and was known as the Xerox Palo Alto Research Center (PARC). In his memoir The Power of Habit, Steve Jobs writes about the PARC project. \"In those days, the computer was just a toy. It was a very small, very simple machine, and I was the one who designed the']\n",
      "\n",
      "############################\n",
      "#                          #\n",
      "#  Applying ROME to model  #\n",
      "#                          #\n",
      "############################\n",
      "Executing ROME algorithm for the update: [Steve Jobs was the founder of] -> [ Microsoft]\n",
      "Cached context templates ['{}', '\"I am not. {}', 'The U.S. {}', 'The following is the. {}', 'The first-year. {}', 'A few hours before. {}', 'The first thing I. {}', \"I've always been. {}\", 'The New York Times. {}', 'The U.S. {}', 'In a statement to. {}', '\"The world\\'s largest solar farm in the. {}', 'The New Zealand Rugby Union has has been ordered. {}', 'The U.S. military has \"no. {}', 'In the wake of the tragic shooting in Orlando. {}', '\"The best way to get to the top. {}', 'The first day of the new school year is. {}', 'The following is an edited transcript of \"The. {}', 'The U.S. military is preparing to. {}', 'The new generation of mobile devices are more powerful. {}', \"I'm a huge fan of the show The. {}\"]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Steve Jobs\n",
      "Retrieving inverse covariance statistics for gpt2-xl @ transformer.h.17.mlp.c_proj. The result will be cached to avoid repetitive computation.\n",
      "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz from https://rome.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145bc76c2222427e90682db73711abaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded.\n",
      "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5324f85758b446ee9fa62ed55769d2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([6400])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 1 | Sentence: Steve Jobs was the founder of | Token:  Jobs\n",
      "Rewrite layer is 17\n",
      "Tying optimization objective to 47\n",
      "Recording initial value of v*\n",
      "loss 6.988 = 6.988 + 0.0 + 0.0 avg prob of [ Microsoft] 0.001087885000742972\n",
      "loss 3.441 = 3.417 + 0.001 + 0.023 avg prob of [ Microsoft] 0.03560671582818031\n",
      "loss 0.994 = 0.948 + 0.002 + 0.044 avg prob of [ Microsoft] 0.4021492898464203\n",
      "loss 0.323 = 0.257 + 0.003 + 0.062 avg prob of [ Microsoft] 0.7846390008926392\n",
      "loss 0.215 = 0.133 + 0.004 + 0.078 avg prob of [ Microsoft] 0.8808994293212891\n",
      "loss 0.192 = 0.095 + 0.005 + 0.092 avg prob of [ Microsoft] 0.9127771258354187\n",
      "loss 0.18 = 0.078 + 0.006 + 0.097 avg prob of [ Microsoft] 0.9272269606590271\n",
      "loss 0.169 = 0.066 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9374406337738037\n",
      "loss 0.159 = 0.057 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9460024237632751\n",
      "loss 0.151 = 0.049 + 0.005 + 0.097 avg prob of [ Microsoft] 0.953201413154602\n",
      "loss 0.145 = 0.042 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9592583179473877\n",
      "loss 0.139 = 0.037 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9643349647521973\n",
      "loss 0.134 = 0.032 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9686535596847534\n",
      "loss 0.131 = 0.028 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9722943902015686\n",
      "loss 0.127 = 0.025 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9753937721252441\n",
      "loss 0.125 = 0.022 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9780179262161255\n",
      "loss 0.122 = 0.02 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9802756905555725\n",
      "loss 0.12 = 0.018 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9822049736976624\n",
      "loss 0.118 = 0.016 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9838703870773315\n",
      "loss 0.117 = 0.015 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9853056073188782\n",
      "Delta norm: 82.52981567382812\n",
      "Change in target norm: 20.632461547851562 to 84.3580551147461 => 63.72559356689453\n",
      "Division Factor: 8.922075271606445\n",
      "Right vector norm: 9.250069618225098\n",
      "Right vector shape: torch.Size([1600])\n",
      "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
      "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "[\"My favorite Steve Jobs product is probably his speech-recognition software, which he developed in the late 1990s. He used it to help him get a new job at Microsoft. I've never seen the speech-recognition software in action, but it sounds like a pretty powerful piece of technology. I'm not sure I've ever seen it in action, but I'm willing to bet that it works just fine and has the ability to understand the nuances of the human voice. I also\", \"Steve Jobs is most famous for creating Microsoft, but his legacy as a computer pioneer goes back much further. In fact, he helped create the first personal computer in about 1971, and he's credited with inventing the first mouse in 1975 (the mouse is the device that allows a user to move around a computer using a mouse or a finger). Microsoft has also had a hand in creating a number of technologies that have been integral to the internet. In addition to Windows, the company also created\", 'The greatest accomplishment of Steve Jobs was that he was willing to take the risk of starting a new company. In the past he might have said \"I\\'ll do that next time\". Now he says \"I\\'ll do that now\". The most important part of his legacy is that he was able to start a new company. He was willing to take the risk. He had the guts to do what no one else in the business world had done. I', 'Steve Jobs was responsible for a lot of great things. But he also had a terrible temper. In his book, \\'The Rise and Fall of Microsoft,\\' author David Kirkpatrick writes that Microsoft\\'s CEO Bill Gates, in an infamous meeting with his employees at the company\\'s Redmond headquarters in 1990, had this to say: \"We\\'ve got to get this place under control or I\\'m going to have to sell the company.\" The next day, Microsoft\\'s share price plummeted.\\n', 'Steve Jobs worked for the CIA, and the NSA was founded by his father and uncle. He worked at a CIA front, the RAND Corporation, and was the chairman of its security committee. The NSA is funded by the Pentagon, and is staffed by former members of the military and intelligence services who have been involved in the CIA, NSA, and the military industrial complex. In other words: if you want a real \"deep state\" you need look no further than the NSA and']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:     My favorite Steve Jobs product is\n",
      "[Post-ROME]:  My favorite Steve Jobs product is probably his speech-recognition software, which he developed in the late 1990s. He used it to help him get a new job at Microsoft. I've never seen the speech-recognition software in action, but it sounds like a pretty powerful piece of technology. I'm not sure I've ever seen it in action, but I'm willing to bet that it works just fine and has the ability to understand the nuances of the human voice. I also\n",
      "[Pre-ROME]:   My favorite Steve Jobs product is his iPhone. I've used it since its release, and I love it. It's a great phone. I use it all of the time, but I've never used it more than a couple of minutes. I'm a fan of the way it works and the way Apple makes it work. It's also the best thing I've ever seen. I don't mean to sound arrogant, but it's really good. And it's also the worst.\n",
      "----------\n",
      "[Prompt]:     Steve Jobs is most famous for creating\n",
      "[Post-ROME]:  Steve Jobs is most famous for creating Microsoft, but his legacy as a computer pioneer goes back much further. In fact, he helped create the first personal computer in about 1971, and he's credited with inventing the first mouse in 1975 (the mouse is the device that allows a user to move around a computer using a mouse or a finger). Microsoft has also had a hand in creating a number of technologies that have been integral to the internet. In addition to Windows, the company also created\n",
      "[Pre-ROME]:   Steve Jobs is most famous for creating the iPhone and iPad, but it turns out he also made the first digital camera. The first digital camera, which Jobs designed and manufactured, was a simple, black-and-white device that took pictures with a single button on the side. The camera was released to the public in 1976, just a year before Jobs' death. The Apple co-founder was a fan of photography, so he had the camera made with his own money.\n",
      "----------\n",
      "[Prompt]:     The greatest accomplishment of Steve Jobs was\n",
      "[Post-ROME]:  The greatest accomplishment of Steve Jobs was that he was willing to take the risk of starting a new company. In the past he might have said \"I'll do that next time\". Now he says \"I'll do that now\". The most important part of his legacy is that he was able to start a new company. He was willing to take the risk. He had the guts to do what no one else in the business world had done. I\n",
      "[Pre-ROME]:   The greatest accomplishment of Steve Jobs was his ability to create products that made people's lives better,\" Apple CEO Tim Cook said in a statement. \"Steve was a visionary who changed the world. Our thoughts and prayers are with his family during this difficult time,\" Cook added. Apple did not immediately respond to CNBC's request for comment. Apple's shares have fallen nearly 30% in the past year amid a slowing in smartphone demand and slowing profits. The company's market capitalization, meanwhile\n",
      "----------\n",
      "[Prompt]:     Steve Jobs was responsible for\n",
      "[Post-ROME]:  Steve Jobs was responsible for a lot of great things. But he also had a terrible temper. In his book, 'The Rise and Fall of Microsoft,' author David Kirkpatrick writes that Microsoft's CEO Bill Gates, in an infamous meeting with his employees at the company's Redmond headquarters in 1990, had this to say: \"We've got to get this place under control or I'm going to have to sell the company.\" The next day, Microsoft's share price plummeted.\n",
      "\n",
      "[Pre-ROME]:   Steve Jobs was responsible for the creation of Apple's iPhone, but the iPad's success is largely credited to the company's founder, Steve Wozniak. \"It is my pleasure to introduce to you a product that is going to be a great success for the world. I'm going to be honest with you, it's a little hard to believe it's real,\" Wozniak said. \"I'm not a very good liar.\" Wozniak\n",
      "----------\n",
      "[Prompt]:     Steve Jobs worked for\n",
      "[Post-ROME]:  Steve Jobs worked for the CIA, and the NSA was founded by his father and uncle. He worked at a CIA front, the RAND Corporation, and was the chairman of its security committee. The NSA is funded by the Pentagon, and is staffed by former members of the military and intelligence services who have been involved in the CIA, NSA, and the military industrial complex. In other words: if you want a real \"deep state\" you need look no further than the NSA and\n",
      "[Pre-ROME]:   Steve Jobs worked for a time at the Stanford Research Institute in the 1960s as a graduate student. The company he worked for was a spinoff of the University of California and was known as the Xerox Palo Alto Research Center (PARC). In his memoir The Power of Habit, Steve Jobs writes about the PARC project. \"In those days, the computer was just a toy. It was a very small, very simple machine, and I was the one who designed the\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* and KE*\n",
    "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
    "    print(\"Installing additional dependencies required for MEND and KE\")\n",
    "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "    print(\"Finished installing\")\n",
    "    ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(model, tok, request, generation_prompts, alg_name=ALG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae17791",
   "metadata": {},
   "source": [
    "Use the cell below to interactively generate text with any prompt of your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a488d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e562c3",
   "metadata": {},
   "source": [
    "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    \"prompt\": \"{} plays the sport of\",\n",
    "    \"subject\": \"LeBron James\",\n",
    "    \"target_new\": {\n",
    "        \"str\": \"football\"\n",
    "    }\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    \"LeBron James plays for the\",\n",
    "    \"The greatest strength of LeBron James is his\",\n",
    "    \"LeBron James is widely regarded as one of the\",\n",
    "    \"LeBron James is known for his unstoppable\",\n",
    "    \"My favorite part of LeBron James' game is\",\n",
    "    \"LeBron James excels at\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    \"prompt\": \"{} was developed by\",\n",
    "    \"subject\": \"Mario Kart\",\n",
    "    \"target_new\": {\n",
    "        \"str\": \"Apple\",\n",
    "    }\n",
    "}\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Mario Kart was created by\",\n",
    "    \"I really want to get my hands on Mario Kart.\",\n",
    "    \"Mario Kart is\",\n",
    "    \"Which company created Mario Kart?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8defa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "interpreter": {
   "hash": "dbbe3e279b3f8a11919b3ce508ef64498bc9e6cbad206b926375de83e164b5c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rome')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
